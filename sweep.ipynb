{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7348cc55-a852-4d36-a822-73c413c09b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luay/.conda/envs/tf/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from datetime import datetime\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from affectnet import AffectNet\n",
    "from dataset_builder import AffectNetDatasetBuilder\n",
    "from data_pipeline import random_flip_left_right, random_rotate, random_translate, random_hue, random_contrast, random_gamma, random_jpeg_quality\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# from callbacks import TelegramNotifier\n",
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a18c80-6328-478e-bd87-49d1f75b2dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luay/.conda/envs/tf/bin/python\n",
      "2.7.0\n",
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb84c8b0-f794-442e-aac1-e7673d30664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: immqshxd\n",
      "Sweep URL: https://wandb.ai/luaygz/FacialEmotionClassifier/sweeps/immqshxd\n",
      "immqshxd\n"
     ]
    }
   ],
   "source": [
    "# sweep_config = {\n",
    "#     \"name\" : \"baseline-sweep\",\n",
    "#     \"method\" : \"bayes\",\n",
    "#     \"metric\": {\n",
    "#         \"name\": \"val_accuracy\",\n",
    "#         \"goal\": \"maximize\"  \n",
    "#     },\n",
    "#     \"parameters\" : {\n",
    "#         \"learning_rate\" :{\n",
    "#             \"min\": math.log(1e-5),\n",
    "#             \"max\": math.log(1e-4),\n",
    "#             \"distribution\": \"log_uniform\"\n",
    "#         },\n",
    "#         \"batch_size\": {\n",
    "#             \"min\": math.log(32),\n",
    "#             \"max\": math.log(96),\n",
    "#             \"distribution\": \"q_log_uniform\"\n",
    "#         },\n",
    "#         \"base_model_output_layer_dropout\": {\n",
    "#             \"min\": 0.0,\n",
    "#             \"max\": 0.8,\n",
    "#             \"distribution\": \"uniform\"\n",
    "#         },\n",
    "#         \"num_middle_layers\": {\n",
    "#             \"min\": 0,\n",
    "#             \"max\": 2,\n",
    "#             \"distribution\": \"int_uniform\"\n",
    "#         },\n",
    "#         \"middle_layer_0\": {\n",
    "#             \"min\": math.log(128),\n",
    "#             \"max\": math.log(1024),\n",
    "#             \"distribution\": \"log_uniform\"\n",
    "#         },\n",
    "#         \"middle_layer_0_dropout\": {\n",
    "#             \"min\": 0.0,\n",
    "#             \"max\": 0.8,\n",
    "#             \"distribution\": \"uniform\"\n",
    "#         },\n",
    "#         \"middle_layer_1\": {\n",
    "#             \"min\": math.log(128),\n",
    "#             \"max\": math.log(1024),\n",
    "#             \"distribution\": \"log_uniform\"\n",
    "#         },\n",
    "#         \"middle_layer_1_dropout\": {\n",
    "#             \"min\": 0.0,\n",
    "#             \"max\": 0.8,\n",
    "#             \"distribution\": \"uniform\"\n",
    "#         },\n",
    "#         \"random_flip_left_right\": {\n",
    "#             \"value\": True,\n",
    "#             \"distribution\": \"constant\"\n",
    "#         },\n",
    "#         \"random_translate\": {\n",
    "#             \"value\": True,\n",
    "#             \"distribution\": \"constant\"\n",
    "#         },\n",
    "#         \"random_hue\": {\n",
    "#             \"value\": True,\n",
    "#             \"distribution\": \"constant\"\n",
    "#         },\n",
    "#         \"random_contrast\": {\n",
    "#             \"value\": True,\n",
    "#             \"distribution\": \"constant\"\n",
    "#         },\n",
    "#         \"random_gamma\": {\n",
    "#             \"value\": True,\n",
    "#             \"distribution\": \"constant\"\n",
    "#         },\n",
    "#         \"random_jpeg_quality\": {\n",
    "#             \"value\": True,\n",
    "#             \"distribution\": \"constant\"\n",
    "#         },\n",
    "#         \"random_rotate\": {\n",
    "#             \"value\": True,\n",
    "#             \"distribution\": \"constant\"\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "# sweep_id = wandb.sweep(sweep_config, project=\"FacialEmotionClassifier\")\n",
    "# print(sweep_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b81481-2a50-4856-89fa-f4fa200658bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_ROOT_DIR = \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd8687c7-d546-45b6-9121-571722d34155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Neutral\", \"Happiness\", \"Sadness\", \"Surprise\", \"Fear\", \"Disgust\", \"Anger\", \"Contempt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba754186-6aec-4eb6-86fa-6d7d3dff08a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    134415\n",
       "0     74874\n",
       "2     25459\n",
       "6     24882\n",
       "3     14090\n",
       "4      6378\n",
       "5      3803\n",
       "7      3750\n",
       "Name: expression, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"dataset/training.csv\")\n",
    "val_df = pd.read_csv(\"dataset/validation.csv\")\n",
    "\n",
    "train_df[\"expression\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39f28823-ddb7-41f4-83bb-0002224a33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.iloc[:1250]\n",
    "# train_df[\"expression\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae48c976-bbbc-4f4e-b709-abe2d7f85274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(config, train_df, val_df, augmentations):\n",
    "    dataset_builder = AffectNetDatasetBuilder(train_df, val_df)\n",
    "\n",
    "    train_dataset, val_dataset = dataset_builder.build(batch_size=config.batch_size,\n",
    "                                                       augmentations=augmentations,\n",
    "                                                       shuffle=True,\n",
    "                                                       seed=0)\n",
    "    class_weights = dataset_builder.get_class_weights()\n",
    "    \n",
    "    return train_dataset, val_dataset, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ec5131-7cb3-490e-993c-0de5e5ebd975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentations(config):\n",
    "    aug = []\n",
    "    if config.random_flip_left_right:\n",
    "        aug.append(random_flip_left_right)\n",
    "    if config.random_translate:\n",
    "        aug.append(random_translate)\n",
    "    if config.random_hue:\n",
    "        aug.append(random_hue)\n",
    "    if config.random_contrast:\n",
    "        aug.append(random_contrast)\n",
    "    if config.random_gamma:\n",
    "        aug.append(random_gamma)\n",
    "    if config.random_jpeg_quality:\n",
    "        aug.append(random_jpeg_quality)\n",
    "    if config.random_rotate:\n",
    "        aug.append(random_rotate)\n",
    "    return aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1d1bc8d-4936-4a35-ade9-14dda255d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model(config, class_weights=None, callbacks=None):\n",
    "    base_model = ResNet50(weights=\"imagenet\", include_top=False)\n",
    "    \n",
    "    if config.num_middle_layers == 0:\n",
    "        middle_layer = None\n",
    "    elif config.num_middle_layers == 1:\n",
    "        middle_layer = Sequential([\n",
    "                                   layers.Dense(config.middle_layer_0, activation=\"relu\"),\n",
    "                                   layers.Dropout(config.middle_layer_0_dropout),\n",
    "                                  ])\n",
    "    elif config.num_middle_layers == 2:\n",
    "        middle_layer = Sequential([\n",
    "                                   layers.Dense(config.middle_layer_0_dropout, activation=\"relu\"),\n",
    "                                   layers.Dropout(config.middle_layer_0_dropout),\n",
    "                                   layers.Dense(config.middle_layer_1, activation=\"relu\"),\n",
    "                                   layers.Dropout(config.middle_layer_1_dropout),\n",
    "                                  ])\n",
    "    affectnet = AffectNet(base_model=base_model,\n",
    "                      base_model_output_dropout=config.base_model_output_layer_dropout,\n",
    "                      middle_layer=middle_layer,\n",
    "                      preprocess_input=preprocess_input,\n",
    "                      class_weights=class_weights,\n",
    "                      # learning_rate=config.learning_rate,\n",
    "                      learning_rate=5e-5,\n",
    "                      callbacks=callbacks)\n",
    "    affectnet.unfreeze(0) # Freeze all\n",
    "    \n",
    "    return affectnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d8f026c-9f3a-4e25-afe8-390d87a02398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks():\n",
    "    checkpoint_dir = datetime.today().strftime(\"%Y-%m-%d-%H:%M:%S\") + \"-\" + wandb.run.name\n",
    "    full_save_path = os.path.join(SAVE_ROOT_DIR, checkpoint_dir)\n",
    "    os.makedirs(full_save_path)\n",
    "    run_id = 0\n",
    "\n",
    "    checkpoint_format = str(run_id) + \"_epoch_{epoch:03d}.val_loss_{val_loss:.4f}\"\n",
    "    filepath = os.path.join(full_save_path, checkpoint_format)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(filepath=filepath,\n",
    "                                          save_weights_only=False,\n",
    "                                          save_format=\"tf\",\n",
    "                                          monitor=\"val_accuracy\",\n",
    "                                          save_freq=\"epoch\")\n",
    "\n",
    "    callbacks = [checkpoint_callback]\n",
    "    # callbacks.append(TelegramNotifier(checkpoint_dir, run_id))\n",
    "    callbacks.append(WandbCallback(save_model=False))\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a57f845e-1cd1-481a-943e-ca5d6c4e2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    with wandb.init() as run:\n",
    "        config = wandb.config\n",
    "        \n",
    "        augmentations = get_augmentations(config)\n",
    "        train_dataset, val_dataset, class_weights = get_dataset(config, train_df, val_df, augmentations)\n",
    "        callbacks = get_callbacks()\n",
    "        affectnet = construct_model(config, class_weights=class_weights, callbacks=callbacks)\n",
    "        \n",
    "        print(affectnet.model.summary())\n",
    "        if affectnet.middle_layer:\n",
    "            print(affectnet.middle_layer.summary())\n",
    "        print(config)\n",
    "        \n",
    "        y_true = []\n",
    "        for batch in val_dataset:\n",
    "            y_true.extend(batch[1].numpy().tolist())\n",
    "        \n",
    "        for epoch in range(3):\n",
    "            affectnet.train(train_dataset=train_dataset, val_dataset=val_dataset, epochs=1)\n",
    "            pred = affectnet.model.predict(val_dataset)\n",
    "            pred = pred[\"output_expression\"]\n",
    "            pred = softmax(pred)\n",
    "            pred = argmax(pred, axis=1)\n",
    "            wandb.log({\"conf_mat\": wandb.plot.confusion_matrix(probs=None,\n",
    "                                                               y_true=y_true, preds=pred,\n",
    "                                                               class_names=class_names)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9702556f-549b-4e1a-a8fb-3ba96b267d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aso014zy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbase_model_output_layer_dropout: 0.6986851781272403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 65\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.767164497867954e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmiddle_layer_0: 645.9481648134051\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmiddle_layer_0_dropout: 0.7029953430271116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmiddle_layer_1: 683.4530064190985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmiddle_layer_1_dropout: 0.1167755431070801\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_middle_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_contrast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_flip_left_right: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_gamma: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_hue: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_jpeg_quality: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_rotate: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_translate: True\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mluaygz\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/luaygz/FacialEmotionClassifier/runs/aso014zy\" target=\"_blank\">different-sweep-1</a></strong> to <a href=\"https://wandb.ai/luaygz/FacialEmotionClassifier\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/luaygz/FacialEmotionClassifier/sweeps/immqshxd\" target=\"_blank\">https://wandb.ai/luaygz/FacialEmotionClassifier/sweeps/immqshxd</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 08:43:03.468189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:43:03.600536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:43:03.600855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:43:03.601931: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-18 08:43:03.603161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:43:03.603466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:43:03.603701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:43:05.360405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:43:05.360720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:43:05.360980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:43:05.361153: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-02-18 08:43:05.361203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9995 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:41:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 287651 training images, and 4000 validation images.\n",
      "Model: \"affect_net_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, None, None, 2048)  23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  multiple                 0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 645)               1321605   \n",
      "                                                                 \n",
      " output_layer (OutputLayer)  multiple                  5168      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,914,485\n",
      "Trainable params: 1,326,773\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 645)               1321605   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 645)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,321,605\n",
      "Trainable params: 1,321,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "{'base_model_output_layer_dropout': 0.6986851781272403, 'batch_size': 65, 'learning_rate': 7.767164497867954e-05, 'middle_layer_0': 645.9481648134051, 'middle_layer_0_dropout': 0.7029953430271116, 'middle_layer_1': 683.4530064190985, 'middle_layer_1_dropout': 0.1167755431070801, 'num_middle_layers': 1, 'random_contrast': True, 'random_flip_left_right': True, 'random_gamma': True, 'random_hue': True, 'random_jpeg_quality': True, 'random_rotate': True, 'random_translate': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 08:43:14.450741: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2022-02-18 08:43:15.782951: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-02-18 08:43:15.783769: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-02-18 08:43:15.783802: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-02-18 08:43:15.784587: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-02-18 08:43:15.784648: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-02-18 08:43:17.667761: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/4426 [..............................] - ETA: 31:12 - loss: 4.1683 - accuracy: 0.1462WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1628s vs `on_train_batch_end` time: 0.2183s). Check your callbacks.\n",
      " 231/4426 [>.............................] - ETA: 29:06 - loss: 3.2009 - accuracy: 0.1402"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n",
      "Process wandb_internal:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luay/.conda/envs/tf/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/luay/.conda/envs/tf/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/luay/.conda/envs/tf/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 159, in wandb_internal\n",
      "    thread.join()\n",
      "  File \"/home/luay/.conda/envs/tf/lib/python3.9/threading.py\", line 1053, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/luay/.conda/envs/tf/lib/python3.9/threading.py\", line 1069, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 49515... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = 1\n",
    "wandb.agent(\"immqshxd\", function=train, count=count, project=\"FacialEmotionClassifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
